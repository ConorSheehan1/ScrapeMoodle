from secret import secretimport requestsimport refrom bs4 import BeautifulSoup, SoupStrainerimport coloramadef parse_link(url):	# links always end with = and some number	# parse from href= until =[some_number(s)], then remove href	return re.findall(r'href=.+=[0-9]+', url)[0].replace('href="', "")def parse_title(url):	# get alphabetical, numerical and some puntuation/spaces between > and < tags	# (?<=>) start matching after > character, (?=<) end matching before < character	return re.findall(r'(?<=>)[a-zA-Z0-9\s._\-]+(?=<)', url)[-1]def download_pdf(title, url):	print("downloading", title, url)	if not title.endswith(".pdf"):		title += ".pdf"	r = session_requests.get(url)	with open(title, "wb") as pdffile:		pdffile.write(r.content)def find_pdfs(url, visited=(), details=True, debug=False):	'''	:param url: address to scrape pdfs from	:param visited: list of folders visited	:param details: print what's being visited and downloaded	:param debug: print error messages if true	:return:	'''	# add current link to visited	visited += (url,)	result = session_requests.get(url, headers=dict(referer=url))	for link in BeautifulSoup(result.content, "lxml", parse_only=SoupStrainer('a')):		current = str(link)		if "pdf" in current:			try:				pdf_url = parse_link(current)				title = parse_title(current)				if details:					print("pdf downloading", title, pdf_url)			# if regex fails to parse pdf			except IndexError:				if debug:					print("failed: pdf", current)		elif "folder" in current:			try:				new_link = parse_link(current)			# if regex fails, skip iteration in loop			except IndexError:				if debug:					print("failed: folder", current)				continue			# if parsed folder link is not the url the method was called on			if new_link not in visited:				if details:					print("visiting folder", new_link)				return find_pdfs(new_link, visited)def get_comp_modules(login_result):	# # get all the links to other COMP courses you're enrolled in from the home page	for link in BeautifulSoup(login_result.content, "lxml", parse_only=SoupStrainer('a')):		current = str(link)		if 'title="COMP' in current:			# allow for spaces between comp and module code, start match after title=" is found			module_code = re.findall(r'(?<=title=")COMP\s*[0-9]+', current)[0]			href = parse_link(current)			print(module_code, href)			find_pdfs(href)session_requests = requests.session()login_url = "https://csmoodle.ucd.ie/moodle/login/index.php"# set up credentials to log inpayload = {	"username": secret.username,	"password": secret.password}# log in to siteresult = session_requests.post(	login_url,	data=payload,	headers=dict(referer=login_url))print("login\t", result.ok, "\t", result.status_code)courses = {}get_comp_modules(result)# scrape data (workplacement thing)# find_pdfs('https://csmoodle.ucd.ie/moodle/course/view.php?id=439')