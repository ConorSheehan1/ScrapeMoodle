from secret import secretimport requestsimport refrom bs4 import BeautifulSoup, SoupStrainerdef parse_link(url):	# links always end with = and some number	# parse from href= until =[some_number(s)], then remove href	return re.findall(r'href=.+=[0-9]+', url)[0].replace('href="', "")def parse_pdf_title(url):	# get alphabetical, numerical and some puntuation/spaces outisde of < tag	# split based on tag and remove remaining tag	return re.findall(r'[a-zA-Z0-9\s._\-]+(?=<)', url)[-1].split("<")[0].replace(">", "")def download_pdf(title, url):	print("downloading", title, url)	if not title.endswith(".pdf"):		title += ".pdf"	r = session_requests.get(url)	with open(title, "wb") as pdffile:		pdffile.write(r.content)def find_pdfs(url, visited=()):	'''	:param url: address to scrape pdfs from	:param visited: list of folders visited	:return:	'''	# break out of recursion	if url in visited:		return	# add current link to visited	visited += (url,)	result = session_requests.get(url, headers=dict(referer=url))	for link in BeautifulSoup(result.content, "lxml", parse_only=SoupStrainer('a')):		current = str(link)		if "pdf" in current:			pdf_url = parse_link(current)			title = parse_pdf_title(current)			# print("pdf", title, pdf_url)			download_pdf(title, pdf_url)		elif "folder" in current:			new_link = parse_link(current)			# print("folder", new_link)			# if parsed folder link is not the url the method was called on			if new_link not in visited:				return find_pdfs(new_link, visited)session_requests = requests.session()login_url = "https://csmoodle.ucd.ie/moodle/login/index.php"result = session_requests.get(login_url)# set up credentials to log inpayload = {	"username": secret.username,	"password": secret.password}# log in to siteresult = session_requests.post(	login_url,	data=payload,	headers=dict(referer=login_url))print("login\t", result.ok, "\t", result.status_code)courses = {}# # get all the links to other COMP courses you're enrolled in from the home page# for link in BeautifulSoup(result.content, parse_only=SoupStrainer('a')):# 	current = str(link)# 	if 'title="COMP' in current:# 		# all for spaces between comp and module code, use [6:] to exclude title=" from code# 		module_code = re.findall(r'title="COMP\s*[0-9]+', current)[0][7:]## 		# name of module should be between two closing span tags. Strip out tags [7:-11]# 		name = re.findall(r'</span>.+</span></a>', current)[0][7:-11]## 		# find link where id= some set of numbers# 		href = re.findall(r'href=.+id=[0-9]+', current)## 		print(module_code, href)# scrape data (workplacement thing)find_pdfs('https://csmoodle.ucd.ie/moodle/course/view.php?id=439')# print("scrape course\t", result.ok, result.status_code)# print(result.content)